{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson 04 ML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLqifLLChxBv22ulTpyAxE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pttrilok/courses/blob/master/Intro%20to%20ML/Lesson%2004%20ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA0PHtN4XP7N"
      },
      "source": [
        "***In this module we are going to learn about***\n",
        "1. Hyper parameters of Random Forest\n",
        "2. Support Vector Machines ( A basic intro)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpCeJ9pkXs1J"
      },
      "source": [
        "***Random Forest Hyperparamters***\n",
        "-------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsij3d-7XKxk"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRe9bSu8X9gt",
        "outputId": "696f74ea-81b1-453b-ef16-a1d9d08337fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rfc= RandomForestClassifier()\n",
        "rfc"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk3bAd5YYLIr"
      },
      "source": [
        "***Following are the hyperparameters we are interested***\n",
        "\n",
        "1. n_estimators\n",
        "2. criterion\n",
        "3. max_depth\n",
        "4. min_samples_split\n",
        "5. min_samples_leaf\n",
        "6. min_weight_fraction_leaf\n",
        "7. max_features\n",
        "8. max_leaf_nodes\n",
        "9. min_impurity_decrease\n",
        "10. bootstrap\n",
        "11. oob_score\n",
        "12. n_jobs\n",
        "13. random_state\n",
        "14. verbose\n",
        "15. warm_start\n",
        "16. class_weight\n",
        "17. ccp_alpha\n",
        "18. max_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ7LN_VfjWb5"
      },
      "source": [
        "***1.) n_estimators***\n",
        "====================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4msDM-fejhsr"
      },
      "source": [
        "It represents number of trees to be used in forest.\n",
        "\n",
        "Default value now a days is 100 earlier it was used to be 10.\n",
        "\n",
        "`What do you think should be the impact of number of estimators on our model?`\n",
        "------------------------------------------------------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvB3CRockzV5"
      },
      "source": [
        "Higher number of trees give you better performance but makes your code slower. You should choose as high value as your processor can handle because this makes your predictions stronger and more stable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwCsbr1pYGQo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHS6ZTtMkydB"
      },
      "source": [
        "***2.) Criterion***\n",
        "==================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrQcq3QhlDlo"
      },
      "source": [
        "`criterion{“gini”, “entropy”}, default=”gini”`\n",
        "This is something related to decision tree we use in random forest. So I believe it should be discussed at the time of discussion of Decision trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RuGnc6NnCkI"
      },
      "source": [
        "***3.) max_depth***\n",
        "==================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlcSWYuTnUek"
      },
      "source": [
        "The max_depth of a tree in Random Forest is defined as the longest path between the root node and the leaf node"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5w9ExJ7npkx"
      },
      "source": [
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Screenshot-2020-03-04-at-15.07.03-768x516.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSc1P26AnwUC"
      },
      "source": [
        "Using the max_depth parameter, I can limit up to what depth I want every tree in my random forest to grow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8-rBinPn6Ii"
      },
      "source": [
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Screenshot-2020-03-04-at-15.08.50-768x741.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO0ldo7hoGSX"
      },
      "source": [
        "In this graph, we can clearly see that as the max depth of the decision tree increases, the performance of the model over the training set increases continuously. On the other hand as the max_depth value increases, the performance over the test set increases initially but after a certain point, it starts to decrease rapidly.\n",
        "\n",
        "Can you think of a reason for this? The tree starts to overfit the training set and therefore is not able to generalize over the unseen points in the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEwggHAfoK_t"
      },
      "source": [
        "***4.) min_sample_split***\n",
        "=========================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_s5pckOoVgZ"
      },
      "source": [
        "***A parameter that tells the decision tree in a random forest the minimum required number of observations in any given node in order to split it***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUYZvHl5or52"
      },
      "source": [
        "1. If int, then consider min_samples_split as the minimum number.\n",
        "\n",
        "2. If float, then min_samples_split is a fraction and `ceil(min_samples_split * n_samples)` are the minimum number of samples for each split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO4ZdSzxpL0q"
      },
      "source": [
        "The default value of the minimum_sample_split is assigned to 2. This means that if any terminal node has more than two observations and is not a pure node, we can split it further into subnodes.\n",
        "\n",
        "Having a default value as 2 poses the issue that a tree often keeps on splitting until the nodes are completely pure. As a result, the tree grows in size and therefore overfits the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrIGdzehpn9g"
      },
      "source": [
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Screenshot-2020-03-04-at-15.11.56-850x290.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSLti8lspshf"
      },
      "source": [
        "By increasing the value of the min_sample_split, we can reduce the number of splits that happen in the decision tree and therefore prevent the model from overfitting. In the above example, if we increase the min_sample_split value from 2 to 6, the tree on the left would then look like the tree on the right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQbJ982bpxhH"
      },
      "source": [
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Screenshot-2020-03-04-at-15.13.06-768x760.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIPAUyDzp5Dy"
      },
      "source": [
        "On increasing the value of the min_sample_split hyperparameter, we can clearly see that for the small value of parameters, there is a significant difference between the training score and the test scores. But as the value of the parameter increases, the difference between the train score and the test score decreases.\n",
        "\n",
        "But there’s one thing you should keep in mind. When the parameter value increases too much, there is an overall dip in both the training score and test scores. This is due to the fact that the minimum requirement of splitting a node is so high that there are no significant splits observed. As a result, the random forest starts to underfit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpREul0fqIyd"
      },
      "source": [
        "***5.) min_samples_leaf***\n",
        "=========================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICuAjbOOrDIW"
      },
      "source": [
        "`min_samples_leafint or float, default=1`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A6eCF5SqTbe"
      },
      "source": [
        "This Random Forest hyperparameter specifies the minimum number of samples that should be present in the leaf node after splitting a node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEFP7nxgq7-_"
      },
      "source": [
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Screenshot-2020-03-04-at-15.34.46-1536x382.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI3-5ADVrMKJ"
      },
      "source": [
        "The tree on the left represents an unconstrained tree. Here, the nodes marked with green color satisfy the condition as they have a minimum of 5 samples. Hence, they will be treated as the leaf or terminal nodes.\n",
        "\n",
        "However, the red node has only 3 samples and hence it will not be considered as the leaf node. Its parent node will become the leaf node. That’s why the tree on the right represents the results when we set the minimum samples for the terminal node as 5.\n",
        "\n",
        "So, we have controlled the growth of the tree by setting a minimum sample criterion for terminal nodes. As you would have guessed, similar to the two hyperparameters mentioned above, this hyperparameter also helps prevent overfitting as the parameter value increases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woC7ehhbt5-f"
      },
      "source": [
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Screenshot-2020-03-04-at-15.41.51-768x743.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_Gn_tiHt8nR"
      },
      "source": [
        "We can clearly see that the Random Forest model is overfitting when the parameter value is very low (when parameter value < 100), but the model performance quickly rises up and rectifies the issue of overfitting (100 < parameter value < 400). But when we keep on increasing the value of the parameter (> 500), the model slowly drifts towards the realm of underfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlRqwVIVuN_s"
      },
      "source": [
        "***6.) min_weight_fraction_leaf***\n",
        "=================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGURNZFNujqx"
      },
      "source": [
        "`min_weight_fraction_leaf float, default=0.0`\n",
        "\n",
        "The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
        "\n",
        "This is quite similar to min_samples_leaf, but it uses a fraction of the sum total number of observations instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjBVxl8dvzao"
      },
      "source": [
        "***7.) max_features***\n",
        "============================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTihSfXNv7OY"
      },
      "source": [
        "`max_features{“auto”, “sqrt”, “log2”}, int or float, default=”auto”`\n",
        "\n",
        "The number of features to consider when looking for the best split:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRWwLWyrwdQU"
      },
      "source": [
        "![](http://scikit-learn.org/stable/_images/sphx_glr_plot_ensemble_oob_001.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_eB0NjjxJYQ"
      },
      "source": [
        "***8.) max_leaf_nodes***\n",
        "======================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y05MfYq5xOgM"
      },
      "source": [
        "This hyperparameter sets a condition on the splitting of the nodes in the tree and hence restricts the growth of the tree. If after splitting we have more terminal nodes than the specified number of terminal nodes, it will stop the splitting and the tree will not grow further.\n",
        "\n",
        "Let’s say we set the maximum terminal nodes as 2 in this case. As there is only one node, it will allow the tree to grow further:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGh0CZNfzWCm"
      },
      "source": [
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Screenshot-2020-03-04-at-15.18.39-768x265.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHnI_mbXzcLS"
      },
      "source": [
        "ow, after the first split, you can see that there are 2 nodes here and we have set the maximum terminal nodes as 2. Hence, the tree will terminate here and will not grow further. This is how setting the maximum terminal nodes or max_leaf_nodes can help us in preventing overfitting.\n",
        "\n",
        "Note that if the value of the max_leaf_nodes is very small, the random forest is likely to underfit. Let’s see how this parameter affects the random forest model’s performance:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buurEKvjzhAO"
      },
      "source": [
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Screenshot-2020-03-04-at-15.21.07-768x734.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmOfQ3FfzrSP"
      },
      "source": [
        "We can see that when the parameter value is very small, the tree is underfitting and as the parameter value increases, the performance of the tree over both test and train increases. According to this plot, the tree starts to overfit as the parameter value goes beyond 25."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rMvLcTZzluu"
      },
      "source": [
        "***9.) min_impurity_decrease***\n",
        "=============================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6iGguvDzyr-"
      },
      "source": [
        "A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
        "\n",
        "That's Something more related to Desision Tree So we will be diving deep into this there"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QzFtpaf07VV"
      },
      "source": [
        "***10.) bootstrap***\n",
        "==========================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9lxvLQz1GDR"
      },
      "source": [
        "`bootstrapbool, default=True`\n",
        "Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
        "\n",
        "More detail about bootstraping has been discussed in previous sessions So I suggest to look at there for better understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_EfF4g71kdQ"
      },
      "source": [
        "***11.) oob_score***\n",
        "=========================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfVFpmSa1p3d"
      },
      "source": [
        "` oob_scorebool, default=False`\n",
        "Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
        "\n",
        "As it is also discussed in the previous sessions -- Specifically in Lesson -2 Machine Learning So refer there for better understanding but I believe that you have revised it  well before this  session "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2IkWJo92Q0T"
      },
      "source": [
        "***12.) n_jobs***\n",
        "==================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH9wtDJH2rzY"
      },
      "source": [
        "`n_jobsint, default=None`\n",
        "and None means 1 here\n",
        "The number of jobs to run in parallel. fit, predict, decision_path and apply are all parallelized over the trees.\n",
        "\n",
        "-1 represents use all processors to achieve target quickly.\n",
        "This is something to boost up the speed of  computation and don't have anything with model accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOtn44EY3TAS"
      },
      "source": [
        "***13. random_state***\n",
        "================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHzjXqKV3WQJ"
      },
      "source": [
        "`random_stateint or RandomState, default=None`\n",
        "\n",
        "Controls both the randomness of the bootstrapping of the samples used when building trees (if bootstrap=True) \n",
        "\n",
        "This is something you encounter everywhere in AI hahahha...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_L-xDsE38Ee"
      },
      "source": [
        "***14.) verbose***\n",
        "==================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-ulbn_P4Af3"
      },
      "source": [
        "`verbose int, default=0`\n",
        "\n",
        "Controls the verbosity when fitting and predicting.\n",
        "\n",
        "Controls both the randomness of the bootstrapping of the samples used when building trees (if bootstrap=True) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5804RB-4tog"
      },
      "source": [
        "***15.) warm_start***\n",
        "==================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkJj8bzj41X3"
      },
      "source": [
        "`warm_start bool, default=False`\n",
        "\n",
        "When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-isxZeDa6Gk3"
      },
      "source": [
        "***16.) class_weight***\n",
        "============================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USTe7bKL6Ltg"
      },
      "source": [
        "`class_weight{“balanced”, “balanced_subsample”}, dict or list of dicts, default=None`\n",
        "\n",
        "It's something that decide penalty kind of thing. Just to unnderstand consider a scenerio that there are 2 classes containing 60 and 40 samples respectively then in the case when model only learn to  give only output as 1 class then also our model will be 60% accurate that should not happen. So we assign something called as class_weight to ensure everything is calculated in a fair way.\n",
        "\n",
        "The “balanced_subsample” mode is the same as “balanced” except that weights are computed based on the bootstrap sample for every tree grown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKeXlbVs9Ejj"
      },
      "source": [
        "***17.) ccp_alpha***\n",
        "======================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-iGOIV9JpI"
      },
      "source": [
        "`ccp_alpha non-negative float, default=0.0`\n",
        "\n",
        "Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ccp_alpha will be chosen. By default, no pruning is performed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MptdAaT91yX"
      },
      "source": [
        "***18.) max_samples***\n",
        "==================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj1vZ-xr-K6M"
      },
      "source": [
        "The max_samples hyperparameter determines what fraction of the original dataset is given to any individual tree. You might be thinking that more data is always better. Let’s try to see if that makes sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_ACdUnj-QgA"
      },
      "source": [
        "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Screenshot-2020-03-04-at-16.04.32-768x481.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O4M4Y4p-ViN"
      },
      "source": [
        "# ***Support Vector Machines***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsRAc59Z-t-W"
      },
      "source": [
        "okayyyyyyyyyyyyyyyyyyyyyy nnow we will be looking into Support vector Machines.\n",
        "This is section is subjected to update.(Screenshots are needed to be updated after the session.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEBdV6zEzpXb"
      },
      "source": [
        "***I know that fact that I didn't write much about explaining the code but I believe I will explain it well hahahahahaha and will update the documentation when I will be free***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCTMPnWD0bp4"
      },
      "source": [
        "***When to use SVM?***\n",
        "1. Binary target Variable\n",
        "2. feature to row ratio is very high\n",
        "3. Very Complex relationships\n",
        "4. Lots of  outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaHW0sXr06x1"
      },
      "source": [
        "***When not to use SVM?***\n",
        "1. Feature to row ratio  is very low\n",
        "2. Transparency is important or interested in significance of predictors\n",
        "3. Looking for a quick benchmark model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUQdhXC_054o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjRVvnROxR8f"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "from sklearn.metrics import classification_report, confusion_matrix \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import load_breast_cancer \n",
        "from sklearn.svm import SVC \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore',category = FutureWarning)\n",
        "warnings.filterwarnings('ignore',category = DeprecationWarning)\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFmxB1Fb32o8"
      },
      "source": [
        "def print_results(results):\n",
        "  print(\"Best Params: {}\\n\".format(results.best_params_))\n",
        "  means = results.cv_results_['mean_test_score']\n",
        "  stds = results.cv_results_[\"std_test_score\"]\n",
        "  for mean,std,params in zip(means,stds,results.cv_results_['params']):\n",
        "    print(\"{} (+/-{}) for {}\" .format(round(mean,3) , round(std*2,3),params))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLFl7ajQ3pky",
        "outputId": "373ae3e7-d96c-4ae9-c76b-105a2237abc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cancer = load_breast_cancer() \n",
        "\n",
        "# The data set is presented in a dictionary form: \n",
        "print(cancer.keys()) \n",
        "tr_features = pd.DataFrame(cancer['data'], columns = cancer['feature_names']) \n",
        "  \n",
        "# cancer column is our target \n",
        "tr_labels = pd.DataFrame(cancer['target'],columns =['Cancer']) \n",
        "  \n",
        "print(\"Feature Variables: \") \n",
        "print(tr_features.info())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
            "Feature Variables: \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8zbo_H8xS1A",
        "outputId": "3147ca5a-aba8-408b-ffc5-733758e62dcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "svc = SVC()\n",
        "parameters = {\n",
        "    \"kernel\" : ['linear','rbf'],\n",
        "    \"C\" :[0.1,1,10]\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(svc,parameters,cv=5)\n",
        "cv.fit(tr_features,tr_labels.values.ravel())\n",
        "print_results(cv)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Params: {'C': 10, 'kernel': 'linear'}\n",
            "\n",
            "0.949 (+/-0.041) for {'C': 0.1, 'kernel': 'linear'}\n",
            "0.891 (+/-0.073) for {'C': 0.1, 'kernel': 'rbf'}\n",
            "0.946 (+/-0.037) for {'C': 1, 'kernel': 'linear'}\n",
            "0.912 (+/-0.071) for {'C': 1, 'kernel': 'rbf'}\n",
            "0.953 (+/-0.028) for {'C': 10, 'kernel': 'linear'}\n",
            "0.923 (+/-0.056) for {'C': 10, 'kernel': 'rbf'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfkSgjFlxXT8",
        "outputId": "9e43ca51-4953-4715-b901-c53ab9ef8506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cv.best_estimator_"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0PbGDwtxmHU",
        "outputId": "521fc430-dfcb-4f34-d1d4-b60bd43517e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cv.best_score_"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9525694767893185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFy6QxBU0DDG",
        "outputId": "c00a91f2-a033-40bb-c267-c9b2f790bf09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sklearn.datasets"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'sklearn.datasets' from '/usr/local/lib/python3.6/dist-packages/sklearn/datasets/__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5JAPF4h0Ggj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}